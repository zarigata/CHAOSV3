# ========================================================================
# C.H.A.O.S. - Ollama AI Integration Configuration
# ========================================================================
# This file configures the Ollama AI integration for C.H.A.O.S.
# Default model is llama3.2 as per project requirements

# General Settings
enabled: true             # Enable/disable Ollama AI features
model: "llama3.2"         # Default model (llama3.2 as required)
api_host: "http://localhost:11434"  # Ollama API host
stream: true              # Stream responses for real-time interaction

# Model Parameters
max_tokens: 1000          # Maximum output tokens
temperature: 0.7          # Response randomness (0.0-1.0)
top_p: 0.9                # Nucleus sampling parameter
top_k: 40                 # Limit vocabulary to top K options

# Custom Behavior
prompt_template: "You are a helpful assistant for C.H.A.O.S. messaging platform."

# Style Configuration
style_options:
  - name: "Standard"
    description: "Normal helpful assistant responses"
    prompt: "You are a helpful assistant."
  
  - name: "Friendly"
    description: "More casual and conversational"
    prompt: "You are a friendly and casual assistant."
  
  - name: "Technical"
    description: "More technical and detailed responses"
    prompt: "You are a technical expert providing detailed information."
  
  - name: "Concise" 
    description: "Brief and to-the-point responses"
    prompt: "You are a concise assistant who provides brief answers."
